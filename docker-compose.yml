version: '3.8'


networks:
  internal_network:
    driver: bridge

services:
  airflow:
  # En caso de falta de contraseña (ver al iniciar sesión en la pagina autohosteada) abrir terminal de contenedor airflow, abrir archivo config y buscar "password": docker ps, docker exec -it <nombre_del_contenedor> bash, /opt/airflow/airflow.cfg, cat /opt/airflow/airflow.cfg
  
    # build:
    #   context: ./airflow-w-sklearn    # <-- Aquí apunta al Dockerfile de la carpeta dedicada
    # image: apache/airflow:2.9.2
    image: matiascollado/airflow-w-sklearn:v1.0
    # image: airflow-w-sklearn
    container_name: airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor #No apto para producción
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__CORE__FERNET__KEY=D_b7-k2tJcEmrfAPASL8V_cY03LJd-uWWtJ-8HN1Esk=
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
      # usuario por defecto
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin
      # # para que todas las carpetas de src/ sean importables
      # - PYTHONPATH=/opt/airflow/src

    volumes: #Los volumenes de airflow los tiene este repo. /data se busca en el repo control
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ../control/data:/opt/airflow/data
      - ./volumes/airflow:/opt/airflow
    
    ports:
      - "8080:8080"
    # command: standalone
    command: >
      bash -c "airflow db init &&
                airflow webserver"


  airflow-scheduler:
    # build:
    #   context: ./airflow-w-sklearn    # <-- Aquí apunta al Dockerfile de la carpeta dedicada
    image: matiascollado/airflow-w-sklearn:v1.0
    # image: airflow-w-sklearn
    container_name: airflow-scheduler
    command: airflow scheduler 
    depends_on:
      - airflow
    volumes: #Los volumenes de airflow los tiene este repo. /data se busca en el repo control
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ../control/data:/opt/airflow/data
      - ./volumes/airflow:/opt/airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor


  mysql-server:
    image: mysql:8.0
    container_name: mysql-server
    environment:
      MYSQL_ROOT_PASSWORD: rootpass
      MYSQL_DATABASE: students
      MYSQL_USER: user
      MYSQL_PASSWORD: 1234
    # ports:
    #   - "3306:3306" # Opcional: solo si necesitas acceder desde fuera del contenedor
    volumes:
      - .volumes/mysql_data:/var/lib/mysql
      - .volumes/mysql_data/init.sql:/docker-entrypoint-initdb.d/init.sql  # script inicial (opcional)
    networks:
      - internal_network
